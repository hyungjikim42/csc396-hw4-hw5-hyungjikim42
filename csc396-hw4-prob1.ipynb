{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fe49e6ac-bd8e-4481-a1ab-2e97b7a17b9e",
   "metadata": {},
   "source": [
    "## NOTE\n",
    "Cyverse kept freezing during the process to the point where it's unusable, so I decided to work on the subset of the original dataset for now. \n",
    "\n",
    "Please comment the line `df = df[0:2500]` if needed!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8d8ecf2-52a7-4ee0-a490-641e9d3c100b",
   "metadata": {},
   "source": [
    "2. Read the texts provided with this assignment (link TBD). Tokenize them using the tokenizer corresponding to the transformer chosen in the previous step. Note that the resulting tokens are sub-word tokens that may not correspond to a full word.\n",
    "3. Generate the contextualized embeddings for all the tokens in the dataset and compute the average embedding for each token in the vocabulary by averaging all its contextualized embeddings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f3a1759a-3962-49f6-801e-7035f347812e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "device: cuda\n",
      "random seed: 2024\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "import torch\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "# enable tqdm in pandas\n",
    "tqdm.pandas()\n",
    "\n",
    "# set to True to use the gpu (if there is one available)\n",
    "use_gpu = True\n",
    "\n",
    "# select device\n",
    "device = torch.device('cuda' if use_gpu and torch.cuda.is_available() else 'cpu')\n",
    "print(f'device: {device.type}')\n",
    "\n",
    "# random seed\n",
    "seed = 2024\n",
    "\n",
    "# set random seed\n",
    "if seed is not None:\n",
    "    print(f'random seed: {seed}')\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6d992958-f541-4d60-9eb4-a701e9787fea",
   "metadata": {},
   "outputs": [],
   "source": [
    "file = 'assignment4-dataset.txt'\n",
    "\n",
    "# read in file as a whole\n",
    "with open(file, 'r') as f:\n",
    "    text = f.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "92fa52d1-592b-44ea-bcda-6407ec5cdc37",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "300935040"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b05f1286-3f8e-4fbb-836d-f49a196b7c6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# split by double new lines\n",
    "split_text = text.split('\\n\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "503d3a83-b834-444f-aba6-0e439b1dd441",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "449919"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(split_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7f11dee5-2e77-4a45-b632-ad726aab0f66",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(split_text, columns=['text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "bc9c9ff8-55c9-4a10-8daa-7e0287a510bb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0         The White Monkey is a 1925 American silent dra...\n",
       "1         Preservation\\nAn incomplete print of The White...\n",
       "2                                            External links\n",
       "3         Films based on works by John Galsworthy\\nFilms...\n",
       "4          the montane grasslands and shrublands biome\\n...\n",
       "                                ...                        \n",
       "449914                                           References\n",
       "449915                                    External links\\n \n",
       "449916    1929 births\\n2015 deaths\\nPeople from Naseby, ...\n",
       "449917    Scottish female golfers\\nGolfers from Edinburg...\n",
       "449918    1868 births\\n1947 deaths\\nGerman Assyriologist...\n",
       "Name: text, Length: 449919, dtype: object"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['text']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "87bcab86-013b-4ffb-bc1a-847f3bb8ef8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# using only a subset\n",
    "# comment to use entire dataset\n",
    "df = df[0:2500]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b62af931-5b28-4ebe-8191-df8e73c91651",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load model directly\n",
    "from transformers import AutoTokenizer, AutoModel, AutoConfig\n",
    "\n",
    "transformer_name=\"Tejas3/distillbert_base_uncased_80_equal\"\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(transformer_name, use_fast=True)\n",
    "model = AutoModel.from_pretrained(transformer_name)\n",
    "\n",
    "model = model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "67335422-80b8-4087-a59a-ded0a5ead5b2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    text: Dataset({\n",
       "        features: ['text'],\n",
       "        num_rows: 2500\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from collections import defaultdict\n",
    "from datasets import Dataset, DatasetDict\n",
    "\n",
    "# use Dataset for batching\n",
    "ds = DatasetDict()\n",
    "\n",
    "ds['text'] = Dataset.from_pandas(df)\n",
    "ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "335cee2f-7997-4b12-a3d7-2ee764229dd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize(batch):\n",
    "    return tokenizer(batch['text'], return_tensors='pt', padding=True, truncation=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f2126cdf-f876-447d-ba0f-a6578d6f969e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e04086dd7c474187aa597dd95bbb2c76",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/2500 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "tokens_ds = ds['text'].map(tokenize, batched=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "id": "bb66f8c3-0f0a-430f-8a7a-b4c300628093",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "datasets.arrow_dataset.Dataset"
      ]
     },
     "execution_count": 156,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(tokens_ds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "843090b9-baa1-48ad-be9e-3806cbbf79a0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>input_ids</th>\n",
       "      <th>attention_mask</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>The White Monkey is a 1925 American silent dra...</td>\n",
       "      <td>[101, 1996, 2317, 10608, 2003, 1037, 4849, 213...</td>\n",
       "      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Preservation\\nAn incomplete print of The White...</td>\n",
       "      <td>[101, 8347, 2019, 12958, 6140, 1997, 1996, 231...</td>\n",
       "      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>External links</td>\n",
       "      <td>[101, 6327, 6971, 102, 0, 0, 0, 0, 0, 0, 0, 0,...</td>\n",
       "      <td>[1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Films based on works by John Galsworthy\\nFilms...</td>\n",
       "      <td>[101, 3152, 2241, 2006, 2573, 2011, 2198, 1489...</td>\n",
       "      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>the montane grasslands and shrublands biome\\n...</td>\n",
       "      <td>[101, 1996, 21704, 26183, 1998, 15751, 8653, 1...</td>\n",
       "      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2495</th>\n",
       "      <td>First implemented in Chicago and New York City...</td>\n",
       "      <td>[101, 2034, 7528, 1999, 3190, 1998, 2047, 2259...</td>\n",
       "      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2496</th>\n",
       "      <td>Smart zoning is a broad term that consists of ...</td>\n",
       "      <td>[101, 6047, 27462, 2003, 1037, 5041, 2744, 200...</td>\n",
       "      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2497</th>\n",
       "      <td>Planned unit development is cluster zoning, bu...</td>\n",
       "      <td>[101, 3740, 3131, 2458, 2003, 9324, 27462, 101...</td>\n",
       "      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2498</th>\n",
       "      <td>Amendments to zoning regulations may be subjec...</td>\n",
       "      <td>[101, 16051, 2000, 27462, 7040, 2089, 2022, 33...</td>\n",
       "      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2499</th>\n",
       "      <td>Land-use zoning is a tool in the treatment of ...</td>\n",
       "      <td>[101, 2455, 1011, 2224, 27462, 2003, 1037, 699...</td>\n",
       "      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2500 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   text  \\\n",
       "0     The White Monkey is a 1925 American silent dra...   \n",
       "1     Preservation\\nAn incomplete print of The White...   \n",
       "2                                        External links   \n",
       "3     Films based on works by John Galsworthy\\nFilms...   \n",
       "4      the montane grasslands and shrublands biome\\n...   \n",
       "...                                                 ...   \n",
       "2495  First implemented in Chicago and New York City...   \n",
       "2496  Smart zoning is a broad term that consists of ...   \n",
       "2497  Planned unit development is cluster zoning, bu...   \n",
       "2498  Amendments to zoning regulations may be subjec...   \n",
       "2499  Land-use zoning is a tool in the treatment of ...   \n",
       "\n",
       "                                              input_ids  \\\n",
       "0     [101, 1996, 2317, 10608, 2003, 1037, 4849, 213...   \n",
       "1     [101, 8347, 2019, 12958, 6140, 1997, 1996, 231...   \n",
       "2     [101, 6327, 6971, 102, 0, 0, 0, 0, 0, 0, 0, 0,...   \n",
       "3     [101, 3152, 2241, 2006, 2573, 2011, 2198, 1489...   \n",
       "4     [101, 1996, 21704, 26183, 1998, 15751, 8653, 1...   \n",
       "...                                                 ...   \n",
       "2495  [101, 2034, 7528, 1999, 3190, 1998, 2047, 2259...   \n",
       "2496  [101, 6047, 27462, 2003, 1037, 5041, 2744, 200...   \n",
       "2497  [101, 3740, 3131, 2458, 2003, 9324, 27462, 101...   \n",
       "2498  [101, 16051, 2000, 27462, 7040, 2089, 2022, 33...   \n",
       "2499  [101, 2455, 1011, 2224, 27462, 2003, 1037, 699...   \n",
       "\n",
       "                                         attention_mask  \n",
       "0     [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...  \n",
       "1     [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...  \n",
       "2     [1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...  \n",
       "3     [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...  \n",
       "4     [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...  \n",
       "...                                                 ...  \n",
       "2495  [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...  \n",
       "2496  [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...  \n",
       "2497  [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...  \n",
       "2498  [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...  \n",
       "2499  [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...  \n",
       "\n",
       "[2500 rows x 3 columns]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokens_ds.to_pandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "011769e0-c4ff-445a-aa56-f88fb3acf4b4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>10</th>\n",
       "      <th>11</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>tokens</th>\n",
       "      <td>[CLS]</td>\n",
       "      <td>scottish</td>\n",
       "      <td>female</td>\n",
       "      <td>golfer</td>\n",
       "      <td>##s</td>\n",
       "      <td>golfer</td>\n",
       "      <td>##s</td>\n",
       "      <td>from</td>\n",
       "      <td>ed</td>\n",
       "      <td>##in</td>\n",
       "      <td>##burg</td>\n",
       "      <td>[SEP]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>word_ids</th>\n",
       "      <td>None</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>input_ids</th>\n",
       "      <td>101</td>\n",
       "      <td>4104</td>\n",
       "      <td>2931</td>\n",
       "      <td>20601</td>\n",
       "      <td>2015</td>\n",
       "      <td>20601</td>\n",
       "      <td>2015</td>\n",
       "      <td>2013</td>\n",
       "      <td>3968</td>\n",
       "      <td>2378</td>\n",
       "      <td>4645</td>\n",
       "      <td>102</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              0         1       2       3     4       5     6     7     8   \\\n",
       "tokens     [CLS]  scottish  female  golfer   ##s  golfer   ##s  from    ed   \n",
       "word_ids    None         0       1       2     2       3     3     4     5   \n",
       "input_ids    101      4104    2931   20601  2015   20601  2015  2013  3968   \n",
       "\n",
       "             9       10     11  \n",
       "tokens     ##in  ##burg  [SEP]  \n",
       "word_ids      5       5   None  \n",
       "input_ids  2378    4645    102  "
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output = tokenizer(\"Scottish female golfers\\nGolfers from Edinburg\")\n",
    "pd.DataFrame(\n",
    "    [output.tokens(), output.word_ids(), output.input_ids],\n",
    "    index=['tokens', 'word_ids', 'input_ids'],\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a67f07c4-7cd1-4169-a71b-e5e2181bc21f",
   "metadata": {},
   "source": [
    "Resulting tokens are sub-word tokens that may not be a full-word.\n",
    "\n",
    "Generate contextualized embedding for all the tokens,\n",
    "compute average embedding for EACH token in the vocab by averaging ALL its contextualized embeddings.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "8b2d9f4e-7d84-4031-acab-3012706b551b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    text: Dataset({\n",
       "        features: ['text'],\n",
       "        num_rows: 1\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test = df[0:1]\n",
    "\n",
    "# use Dataset for batching\n",
    "ds_test = DatasetDict()\n",
    "\n",
    "ds_test['text'] = Dataset.from_pandas(df_test)\n",
    "ds_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "id": "ff275b84-b6ae-4057-96a5-6f10bd08f455",
   "metadata": {},
   "outputs": [],
   "source": [
    "config = AutoConfig.from_pretrained(transformer_name)\n",
    "\n",
    "# dict to popularize and use later for averaging\n",
    "emb_dict = defaultdict(lambda: torch.zeros(config.hidden_size).to(device))\n",
    "count_dict = defaultdict(int)\n",
    "\n",
    "\n",
    "def process(batch):\n",
    "    tokenized_batch = tokenizer(batch['text'], padding=True, truncation=True, return_tensors='pt').to(device)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        output = model(**tokenized_batch)\n",
    "\n",
    "    # extract embedding for the batch\n",
    "    hidden_state = output.last_hidden_state\n",
    "\n",
    "    token_ids = tokenized_batch['input_ids'][0]\n",
    "    for i, input_id in enumerate(token_ids):\n",
    "        token = tokenizer.decode(input_id)\n",
    "        emb = hidden_state[0, i]\n",
    "\n",
    "        emb_dict[token] += emb\n",
    "        count_dict[token] += 1\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "id": "b6fe6bb4-703c-4a92-a7dd-63541d0c0ef1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9260a34efd8049d797c0cfe8e2f30f14",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/2500 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    text: Dataset({\n",
       "        features: ['text'],\n",
       "        num_rows: 2500\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 134,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ds.map(process)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "id": "1e652e8a-61a2-468b-9ad1-5b1636727963",
   "metadata": {},
   "outputs": [],
   "source": [
    "averaged_embeddings = {}\n",
    "\n",
    "for token, emb_sum in emb_dict.items():\n",
    "    count = count_dict[token]\n",
    "    avg_emb = emb_sum / count\n",
    "    averaged_embeddings[token] = avg_emb\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "id": "31d25e2c-5b64-4a99-921d-6599ac1087b2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "18984"
      ]
     },
     "execution_count": 142,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(averaged_embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "id": "afcba025-97e2-495b-b4f4-8f7a3d90aa75",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([-0.4808, -0.0273,  0.1218, -0.0136,  1.7032,  0.4736, -0.7008,  0.6053,\n",
       "         0.3015,  0.3568,  0.4151, -0.4070, -0.0592, -0.2390, -0.8317,  0.0172,\n",
       "         0.2599,  0.3683,  0.6968,  0.0497], device='cuda:0')"
      ]
     },
     "execution_count": 150,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "averaged_embeddings['bank'][:20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "id": "701048a5-27af-4431-afe6-48b84c291459",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([-0.4516, -0.0497,  0.4426, -0.0465,  1.9454,  0.3642, -0.7740,  0.1438,\n",
       "         0.0791,  0.2405,  0.4439, -0.5630, -0.0471, -0.3022, -0.7502,  0.0564,\n",
       "         0.2107,  0.1833,  0.2419, -0.0805], device='cuda:0')"
      ]
     },
     "execution_count": 151,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "averaged_embeddings['##bank'][:20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "id": "a3b7a880-4f9b-4e6f-abfd-96b8742b0353",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([-1.1211,  0.4314,  0.2021,  0.0670,  0.8984,  0.0598,  0.1892,  0.2609,\n",
       "        -0.0384,  0.1633, -0.0507, -0.6512, -0.5906, -0.3929, -0.1859,  0.5465,\n",
       "         0.4533, -0.3638,  0.1692,  0.2941], device='cuda:0')"
      ]
     },
     "execution_count": 152,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "averaged_embeddings['a'][:20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "id": "16c025c1-3b5b-4171-bda7-8b8bf9d0f1d8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([-0.9624,  0.5725,  0.1105, -0.0946,  0.7890,  0.0748, -0.0712,  0.1090,\n",
       "         0.2990, -0.1849,  0.1319, -0.5593, -0.6327, -0.6839, -0.0825,  0.7745,\n",
       "         0.3140, -0.3574,  0.1573,  0.3212], device='cuda:0')"
      ]
     },
     "execution_count": 153,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "averaged_embeddings['an'][:20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "id": "19beedc9-b982-418f-abcc-8ca11154ce82",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([-0.8990,  0.6184,  0.4240, -0.5523,  0.6293, -0.0699,  0.2768,  0.7017,\n",
       "         0.1377,  0.0261,  0.2182, -0.6507, -0.7590, -0.3453, -0.7088,  0.6377,\n",
       "         0.5229, -0.5063,  0.0275,  0.3943], device='cuda:0')"
      ]
     },
     "execution_count": 154,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "averaged_embeddings['what'][:20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62e5cf4c-232d-4dd1-8124-37e22fc89cea",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch-gpu",
   "language": "python",
   "name": "pytorch-gpu"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
