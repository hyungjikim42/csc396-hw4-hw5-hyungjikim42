{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c869ddaf-0c5e-49ef-81dc-8500dfd01b61",
   "metadata": {},
   "source": [
    "Implement an extractive question answering (QA) system using the classifier described in Section 16.6.1. We will discuss this approach in class. Train the classifier using the training partition of the SQuAD 1.1 dataset, and report the Exact Match score on the development partition. Include the scores you obtain in the repository notebook. How do your scores compare with the ones reported in Table 5 in the 2016 SQuAD 1.1 paper?\n",
    " \n",
    "Note: the SQuAD 1.1 dataset and paper are available here: https://rajpurkar.github.io/SQuAD-explorer/"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a804d3c-311c-4104-ae2e-fadad5080722",
   "metadata": {},
   "source": [
    "Most of today’s extractive QA approaches follow the architecture in- troduced in (Devlin et al., 2018), which is based on Figure 12.4 from Chapter 12. In particular, extractive QA methods concatenate the in- put question and supporting passage into a single sequence, where the two texts are separated by [SEP]. For example, the input corresponding to the third question from Figure 16.12 is:10\n",
    "[CLS] Where do water droplets collide with ice crystals to form precipitation? [SEP] In meteorology, precipitation is [...] smaller droplets coalesce via collision with other rain drops or ice crystals within a cloud. Short, intense periods of rain in scattered locations are called “showers.” [SEP]\n",
    "Note that the transformer library will handle the generation of the po- sition and segment embeddings shown in Figure 12.4."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a1424c58-12c6-4788-9692-50c4535d6224",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "device: cuda\n",
      "random seed: 2024\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "import torch\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "# enable tqdm in pandas\n",
    "tqdm.pandas()\n",
    "\n",
    "# set to True to use the gpu (if there is one available)\n",
    "use_gpu = True\n",
    "\n",
    "# select device\n",
    "device = torch.device('cuda' if use_gpu and torch.cuda.is_available() else 'cpu')\n",
    "print(f'device: {device.type}')\n",
    "\n",
    "# random seed\n",
    "seed = 2024\n",
    "\n",
    "# set random seed\n",
    "if seed is not None:\n",
    "    print(f'random seed: {seed}')\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2a04a308-8529-4369-9ab0-a3ce30badb1e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForQuestionAnswering were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['qa_outputs.bias', 'qa_outputs.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "from transformers import BertTokenizerFast, BertForQuestionAnswering\n",
    "import torch\n",
    "\n",
    "model_name = \"bert-base-uncased\"\n",
    "tokenizer = BertTokenizerFast.from_pretrained(model_name)\n",
    "model = BertForQuestionAnswering.from_pretrained(model_name)\n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr=2e-5)\n",
    "\n",
    "model = model.to(device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b8f08766-12e2-4403-829e-846a8ebe7e71",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_dataset\n",
    "dataset = load_dataset(\"squad\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "80763fb5-01a9-4c38-8986-c3a9c9425521",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['id', 'title', 'context', 'question', 'answers'],\n",
       "        num_rows: 87599\n",
       "    })\n",
       "    validation: Dataset({\n",
       "        features: ['id', 'title', 'context', 'question', 'answers'],\n",
       "        num_rows: 10570\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c7b2dbf8-6f52-4098-8853-01e70eedb675",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>title</th>\n",
       "      <th>context</th>\n",
       "      <th>question</th>\n",
       "      <th>answers</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>56be4db0acb8001400a502ec</td>\n",
       "      <td>Super_Bowl_50</td>\n",
       "      <td>Super Bowl 50 was an American football game to...</td>\n",
       "      <td>Which NFL team represented the AFC at Super Bo...</td>\n",
       "      <td>{'text': ['Denver Broncos', 'Denver Broncos', ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>56be4db0acb8001400a502ed</td>\n",
       "      <td>Super_Bowl_50</td>\n",
       "      <td>Super Bowl 50 was an American football game to...</td>\n",
       "      <td>Which NFL team represented the NFC at Super Bo...</td>\n",
       "      <td>{'text': ['Carolina Panthers', 'Carolina Panth...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>56be4db0acb8001400a502ee</td>\n",
       "      <td>Super_Bowl_50</td>\n",
       "      <td>Super Bowl 50 was an American football game to...</td>\n",
       "      <td>Where did Super Bowl 50 take place?</td>\n",
       "      <td>{'text': ['Santa Clara, California', 'Levi's S...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>56be4db0acb8001400a502ef</td>\n",
       "      <td>Super_Bowl_50</td>\n",
       "      <td>Super Bowl 50 was an American football game to...</td>\n",
       "      <td>Which NFL team won Super Bowl 50?</td>\n",
       "      <td>{'text': ['Denver Broncos', 'Denver Broncos', ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>56be4db0acb8001400a502f0</td>\n",
       "      <td>Super_Bowl_50</td>\n",
       "      <td>Super Bowl 50 was an American football game to...</td>\n",
       "      <td>What color was used to emphasize the 50th anni...</td>\n",
       "      <td>{'text': ['gold', 'gold', 'gold'], 'answer_sta...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10565</th>\n",
       "      <td>5737aafd1c456719005744fb</td>\n",
       "      <td>Force</td>\n",
       "      <td>The pound-force has a metric counterpart, less...</td>\n",
       "      <td>What is the metric term less used than the New...</td>\n",
       "      <td>{'text': ['kilogram-force', 'pound-force', 'ki...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10566</th>\n",
       "      <td>5737aafd1c456719005744fc</td>\n",
       "      <td>Force</td>\n",
       "      <td>The pound-force has a metric counterpart, less...</td>\n",
       "      <td>What is the kilogram-force sometimes reffered ...</td>\n",
       "      <td>{'text': ['kilopond', 'kilopond', 'kilopond', ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10567</th>\n",
       "      <td>5737aafd1c456719005744fd</td>\n",
       "      <td>Force</td>\n",
       "      <td>The pound-force has a metric counterpart, less...</td>\n",
       "      <td>What is a very seldom used unit of mass in the...</td>\n",
       "      <td>{'text': ['slug', 'metric slug', 'metric slug'...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10568</th>\n",
       "      <td>5737aafd1c456719005744fe</td>\n",
       "      <td>Force</td>\n",
       "      <td>The pound-force has a metric counterpart, less...</td>\n",
       "      <td>What seldom used term of a unit of force equal...</td>\n",
       "      <td>{'text': ['kip', 'kip', 'kip', 'kip', 'kip'], ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10569</th>\n",
       "      <td>5737aafd1c456719005744ff</td>\n",
       "      <td>Force</td>\n",
       "      <td>The pound-force has a metric counterpart, less...</td>\n",
       "      <td>What is the seldom used force unit equal to on...</td>\n",
       "      <td>{'text': ['sthène', 'sthène', 'sthène', 'sthèn...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10570 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                             id          title  \\\n",
       "0      56be4db0acb8001400a502ec  Super_Bowl_50   \n",
       "1      56be4db0acb8001400a502ed  Super_Bowl_50   \n",
       "2      56be4db0acb8001400a502ee  Super_Bowl_50   \n",
       "3      56be4db0acb8001400a502ef  Super_Bowl_50   \n",
       "4      56be4db0acb8001400a502f0  Super_Bowl_50   \n",
       "...                         ...            ...   \n",
       "10565  5737aafd1c456719005744fb          Force   \n",
       "10566  5737aafd1c456719005744fc          Force   \n",
       "10567  5737aafd1c456719005744fd          Force   \n",
       "10568  5737aafd1c456719005744fe          Force   \n",
       "10569  5737aafd1c456719005744ff          Force   \n",
       "\n",
       "                                                 context  \\\n",
       "0      Super Bowl 50 was an American football game to...   \n",
       "1      Super Bowl 50 was an American football game to...   \n",
       "2      Super Bowl 50 was an American football game to...   \n",
       "3      Super Bowl 50 was an American football game to...   \n",
       "4      Super Bowl 50 was an American football game to...   \n",
       "...                                                  ...   \n",
       "10565  The pound-force has a metric counterpart, less...   \n",
       "10566  The pound-force has a metric counterpart, less...   \n",
       "10567  The pound-force has a metric counterpart, less...   \n",
       "10568  The pound-force has a metric counterpart, less...   \n",
       "10569  The pound-force has a metric counterpart, less...   \n",
       "\n",
       "                                                question  \\\n",
       "0      Which NFL team represented the AFC at Super Bo...   \n",
       "1      Which NFL team represented the NFC at Super Bo...   \n",
       "2                    Where did Super Bowl 50 take place?   \n",
       "3                      Which NFL team won Super Bowl 50?   \n",
       "4      What color was used to emphasize the 50th anni...   \n",
       "...                                                  ...   \n",
       "10565  What is the metric term less used than the New...   \n",
       "10566  What is the kilogram-force sometimes reffered ...   \n",
       "10567  What is a very seldom used unit of mass in the...   \n",
       "10568  What seldom used term of a unit of force equal...   \n",
       "10569  What is the seldom used force unit equal to on...   \n",
       "\n",
       "                                                 answers  \n",
       "0      {'text': ['Denver Broncos', 'Denver Broncos', ...  \n",
       "1      {'text': ['Carolina Panthers', 'Carolina Panth...  \n",
       "2      {'text': ['Santa Clara, California', 'Levi's S...  \n",
       "3      {'text': ['Denver Broncos', 'Denver Broncos', ...  \n",
       "4      {'text': ['gold', 'gold', 'gold'], 'answer_sta...  \n",
       "...                                                  ...  \n",
       "10565  {'text': ['kilogram-force', 'pound-force', 'ki...  \n",
       "10566  {'text': ['kilopond', 'kilopond', 'kilopond', ...  \n",
       "10567  {'text': ['slug', 'metric slug', 'metric slug'...  \n",
       "10568  {'text': ['kip', 'kip', 'kip', 'kip', 'kip'], ...  \n",
       "10569  {'text': ['sthène', 'sthène', 'sthène', 'sthèn...  \n",
       "\n",
       "[10570 rows x 5 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset['validation'].to_pandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "014a1728-86d5-4f6d-9e84-ddf8513015b5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>title</th>\n",
       "      <th>context</th>\n",
       "      <th>question</th>\n",
       "      <th>answers</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5733be284776f41900661182</td>\n",
       "      <td>University_of_Notre_Dame</td>\n",
       "      <td>Architecturally, the school has a Catholic cha...</td>\n",
       "      <td>To whom did the Virgin Mary allegedly appear i...</td>\n",
       "      <td>{'text': ['Saint Bernadette Soubirous'], 'answ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5733be284776f4190066117f</td>\n",
       "      <td>University_of_Notre_Dame</td>\n",
       "      <td>Architecturally, the school has a Catholic cha...</td>\n",
       "      <td>What is in front of the Notre Dame Main Building?</td>\n",
       "      <td>{'text': ['a copper statue of Christ'], 'answe...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5733be284776f41900661180</td>\n",
       "      <td>University_of_Notre_Dame</td>\n",
       "      <td>Architecturally, the school has a Catholic cha...</td>\n",
       "      <td>The Basilica of the Sacred heart at Notre Dame...</td>\n",
       "      <td>{'text': ['the Main Building'], 'answer_start'...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5733be284776f41900661181</td>\n",
       "      <td>University_of_Notre_Dame</td>\n",
       "      <td>Architecturally, the school has a Catholic cha...</td>\n",
       "      <td>What is the Grotto at Notre Dame?</td>\n",
       "      <td>{'text': ['a Marian place of prayer and reflec...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5733be284776f4190066117e</td>\n",
       "      <td>University_of_Notre_Dame</td>\n",
       "      <td>Architecturally, the school has a Catholic cha...</td>\n",
       "      <td>What sits on top of the Main Building at Notre...</td>\n",
       "      <td>{'text': ['a golden statue of the Virgin Mary'...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>87594</th>\n",
       "      <td>5735d259012e2f140011a09d</td>\n",
       "      <td>Kathmandu</td>\n",
       "      <td>Kathmandu Metropolitan City (KMC), in order to...</td>\n",
       "      <td>In what US state did Kathmandu first establish...</td>\n",
       "      <td>{'text': ['Oregon'], 'answer_start': [229]}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>87595</th>\n",
       "      <td>5735d259012e2f140011a09e</td>\n",
       "      <td>Kathmandu</td>\n",
       "      <td>Kathmandu Metropolitan City (KMC), in order to...</td>\n",
       "      <td>What was Yangon previously known as?</td>\n",
       "      <td>{'text': ['Rangoon'], 'answer_start': [414]}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>87596</th>\n",
       "      <td>5735d259012e2f140011a09f</td>\n",
       "      <td>Kathmandu</td>\n",
       "      <td>Kathmandu Metropolitan City (KMC), in order to...</td>\n",
       "      <td>With what Belorussian city does Kathmandu have...</td>\n",
       "      <td>{'text': ['Minsk'], 'answer_start': [476]}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>87597</th>\n",
       "      <td>5735d259012e2f140011a0a0</td>\n",
       "      <td>Kathmandu</td>\n",
       "      <td>Kathmandu Metropolitan City (KMC), in order to...</td>\n",
       "      <td>In what year did Kathmandu create its initial ...</td>\n",
       "      <td>{'text': ['1975'], 'answer_start': [199]}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>87598</th>\n",
       "      <td>5735d259012e2f140011a0a1</td>\n",
       "      <td>Kathmandu</td>\n",
       "      <td>Kathmandu Metropolitan City (KMC), in order to...</td>\n",
       "      <td>What is KMC an initialism of?</td>\n",
       "      <td>{'text': ['Kathmandu Metropolitan City'], 'ans...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>87599 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                             id                     title  \\\n",
       "0      5733be284776f41900661182  University_of_Notre_Dame   \n",
       "1      5733be284776f4190066117f  University_of_Notre_Dame   \n",
       "2      5733be284776f41900661180  University_of_Notre_Dame   \n",
       "3      5733be284776f41900661181  University_of_Notre_Dame   \n",
       "4      5733be284776f4190066117e  University_of_Notre_Dame   \n",
       "...                         ...                       ...   \n",
       "87594  5735d259012e2f140011a09d                 Kathmandu   \n",
       "87595  5735d259012e2f140011a09e                 Kathmandu   \n",
       "87596  5735d259012e2f140011a09f                 Kathmandu   \n",
       "87597  5735d259012e2f140011a0a0                 Kathmandu   \n",
       "87598  5735d259012e2f140011a0a1                 Kathmandu   \n",
       "\n",
       "                                                 context  \\\n",
       "0      Architecturally, the school has a Catholic cha...   \n",
       "1      Architecturally, the school has a Catholic cha...   \n",
       "2      Architecturally, the school has a Catholic cha...   \n",
       "3      Architecturally, the school has a Catholic cha...   \n",
       "4      Architecturally, the school has a Catholic cha...   \n",
       "...                                                  ...   \n",
       "87594  Kathmandu Metropolitan City (KMC), in order to...   \n",
       "87595  Kathmandu Metropolitan City (KMC), in order to...   \n",
       "87596  Kathmandu Metropolitan City (KMC), in order to...   \n",
       "87597  Kathmandu Metropolitan City (KMC), in order to...   \n",
       "87598  Kathmandu Metropolitan City (KMC), in order to...   \n",
       "\n",
       "                                                question  \\\n",
       "0      To whom did the Virgin Mary allegedly appear i...   \n",
       "1      What is in front of the Notre Dame Main Building?   \n",
       "2      The Basilica of the Sacred heart at Notre Dame...   \n",
       "3                      What is the Grotto at Notre Dame?   \n",
       "4      What sits on top of the Main Building at Notre...   \n",
       "...                                                  ...   \n",
       "87594  In what US state did Kathmandu first establish...   \n",
       "87595               What was Yangon previously known as?   \n",
       "87596  With what Belorussian city does Kathmandu have...   \n",
       "87597  In what year did Kathmandu create its initial ...   \n",
       "87598                      What is KMC an initialism of?   \n",
       "\n",
       "                                                 answers  \n",
       "0      {'text': ['Saint Bernadette Soubirous'], 'answ...  \n",
       "1      {'text': ['a copper statue of Christ'], 'answe...  \n",
       "2      {'text': ['the Main Building'], 'answer_start'...  \n",
       "3      {'text': ['a Marian place of prayer and reflec...  \n",
       "4      {'text': ['a golden statue of the Virgin Mary'...  \n",
       "...                                                  ...  \n",
       "87594        {'text': ['Oregon'], 'answer_start': [229]}  \n",
       "87595       {'text': ['Rangoon'], 'answer_start': [414]}  \n",
       "87596         {'text': ['Minsk'], 'answer_start': [476]}  \n",
       "87597          {'text': ['1975'], 'answer_start': [199]}  \n",
       "87598  {'text': ['Kathmandu Metropolitan City'], 'ans...  \n",
       "\n",
       "[87599 rows x 5 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset['train'].to_pandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "54f033e0-1161-4c2f-9d37-23af403d5692",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'id': '572a2a293f37b31900478766',\n",
       " 'title': 'Digimon',\n",
       " 'context': \"The second Digimon series is direct continuation of the first one, and began airing on April 2, 2000. Three years later, with most of the original DigiDestined now in high school at age fourteen, the Digital World was supposedly secure and peaceful. However, a new evil has appeared in the form of the Digimon Emperor (Digimon Kaiser) who as opposed to previous enemies is a human just like the DigiDestined. The Digimon Emperor has been enslaving Digimon with Dark Rings and Control Spires and has somehow made regular Digivolution impossible. However, five set Digi-Eggs with engraved emblems had been appointed to three new DigiDestined along with T.K. and Kari, two of the DigiDestined from the previous series. This new evolutionary process, dubbed Armor Digivolution helps the new DigiDestined to defeat evil lurking in the Digital World. Eventually, the DigiDestined defeat the Digimon Emperor, more commonly known as Ken Ichijouji on Earth, only with the great sacrifice of Ken's own Digimon, Wormmon. Just when things were thought to be settled, new Digimon enemies made from the deactivated Control Spires start to appear and cause trouble in the Digital World. To atone for his past mistakes, Ken joins the DigiDestined, being a DigiDestined himself, with his Partner Wormmon revived to fight against them. They soon save countries including France and Australia from control spires and defeat MaloMyotismon (BelialVamdemon), the digivolved form of Myotismon (Vamdemon) from the previous series. They stop the evil from destroying the two worlds, and at the end, every person on Earth gains their own Digimon partner.\",\n",
       " 'question': 'What age are the original DigiDestined now that they are in High School?',\n",
       " 'answers': {'text': ['fourteen'], 'answer_start': [186]}}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset['train'][54321]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f36e4fd2-21e0-46b3-8d37-319fd05cb07a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['id', 'title', 'context', 'question', 'answers'],\n",
       "    num_rows: 0\n",
       "})"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# https://huggingface.co/learn/nlp-course/en/chapter7/7\n",
    "dataset[\"train\"].filter(lambda x: len(x[\"answers\"][\"text\"]) != 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "58dea59e-9f33-4d6a-904a-e8d32cf86c12",
   "metadata": {},
   "outputs": [],
   "source": [
    "max_length = 384\n",
    "stride = 128\n",
    "\n",
    "def preprocess_training_examples(examples):\n",
    "    questions = [q.strip() for q in examples[\"question\"]]\n",
    "    inputs = tokenizer(\n",
    "        questions,\n",
    "        examples[\"context\"],\n",
    "        max_length=max_length,\n",
    "        truncation=\"only_second\",\n",
    "        stride=stride,\n",
    "        return_overflowing_tokens=True,\n",
    "        return_offsets_mapping=True,\n",
    "        padding=\"max_length\",\n",
    "    )\n",
    "\n",
    "    offset_mapping = inputs.pop(\"offset_mapping\")\n",
    "    sample_map = inputs.pop(\"overflow_to_sample_mapping\")\n",
    "    answers = examples[\"answers\"]\n",
    "    start_positions = []\n",
    "    end_positions = []\n",
    "\n",
    "    for i, offset in enumerate(offset_mapping):\n",
    "        sample_idx = sample_map[i]\n",
    "        answer = answers[sample_idx]\n",
    "        start_char = answer[\"answer_start\"][0]\n",
    "        end_char = answer[\"answer_start\"][0] + len(answer[\"text\"][0])\n",
    "        sequence_ids = inputs.sequence_ids(i)\n",
    "\n",
    "        # Find the start and end of the context\n",
    "        idx = 0\n",
    "        while sequence_ids[idx] != 1:\n",
    "            idx += 1\n",
    "        context_start = idx\n",
    "        while sequence_ids[idx] == 1:\n",
    "            idx += 1\n",
    "        context_end = idx - 1\n",
    "\n",
    "        # If the answer is not fully inside the context, label is (0, 0)\n",
    "        if offset[context_start][0] > start_char or offset[context_end][1] < end_char:\n",
    "            start_positions.append(0)\n",
    "            end_positions.append(0)\n",
    "        else:\n",
    "            # Otherwise it's the start and end token positions\n",
    "            idx = context_start\n",
    "            while idx <= context_end and offset[idx][0] <= start_char:\n",
    "                idx += 1\n",
    "            start_positions.append(idx - 1)\n",
    "\n",
    "            idx = context_end\n",
    "            while idx >= context_start and offset[idx][1] >= end_char:\n",
    "                idx -= 1\n",
    "            end_positions.append(idx + 1)\n",
    "\n",
    "    inputs[\"start_positions\"] = start_positions\n",
    "    inputs[\"end_positions\"] = end_positions\n",
    "    return inputs.to(device)\n",
    "\n",
    "\n",
    "\n",
    "def preprocess_training_examples(examples):\n",
    "    questions = [q.strip() for q in examples[\"question\"]]\n",
    "    inputs = tokenizer(\n",
    "        questions,\n",
    "        examples[\"context\"],\n",
    "        max_length=384,\n",
    "        truncation=\"only_second\",\n",
    "        stride=128,\n",
    "        return_overflowing_tokens=True,\n",
    "        return_offsets_mapping=True,\n",
    "        padding=\"max_length\",\n",
    "    )\n",
    "\n",
    "    offset_mapping = inputs.pop(\"offset_mapping\")\n",
    "    sample_map = inputs.pop(\"overflow_to_sample_mapping\")\n",
    "    answers = examples[\"answers\"]\n",
    "    start_positions = []\n",
    "    end_positions = []\n",
    "\n",
    "    for i, offset in enumerate(offset_mapping):\n",
    "        sample_idx = sample_map[i]\n",
    "        answer = answers[sample_idx]\n",
    "        \n",
    "        # Handle case where no answer exists\n",
    "        if len(answer[\"answer_start\"]) == 0:\n",
    "            start_positions.append(0)\n",
    "            end_positions.append(0)\n",
    "            continue\n",
    "\n",
    "        start_char = answer[\"answer_start\"][0]\n",
    "        end_char = start_char + len(answer[\"text\"][0])\n",
    "        \n",
    "        sequence_ids = inputs.sequence_ids(i)\n",
    "\n",
    "        # Find the start and end of the context\n",
    "        idx = 0\n",
    "        while sequence_ids[idx] != 1:\n",
    "            idx += 1\n",
    "        context_start = idx\n",
    "        \n",
    "        while sequence_ids[idx] == 1:\n",
    "            idx += 1\n",
    "        context_end = idx - 1\n",
    "\n",
    "        # Check if answer is fully inside the context\n",
    "        if offset[context_start][0] > start_char or offset[context_end][1] < end_char:\n",
    "            start_positions.append(0)\n",
    "            end_positions.append(0)\n",
    "        else:\n",
    "            # Find start position\n",
    "            idx = context_start\n",
    "            while idx <= context_end and offset[idx][0] <= start_char:\n",
    "                idx += 1\n",
    "            start_positions.append(idx - 1)\n",
    "\n",
    "            # Find end position\n",
    "            idx = context_end\n",
    "            while idx >= context_start and offset[idx][1] >= end_char:\n",
    "                idx -= 1\n",
    "            end_positions.append(idx + 1)\n",
    "\n",
    "    # Add start and end positions to inputs\n",
    "    inputs[\"start_positions\"] = start_positions\n",
    "    inputs[\"end_positions\"] = end_positions\n",
    "    \n",
    "    return inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c39118e4-b0da-4b64-9e88-9fe6ab8ea2b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_validation_examples(examples):\n",
    "    questions = [q.strip() for q in examples[\"question\"]]\n",
    "    inputs = tokenizer(\n",
    "        questions,\n",
    "        examples[\"context\"],\n",
    "        max_length=384,\n",
    "        truncation=\"only_second\",\n",
    "        stride=128,\n",
    "        return_overflowing_tokens=True,\n",
    "        return_offsets_mapping=True,\n",
    "        padding=\"max_length\",\n",
    "    )\n",
    "\n",
    "    sample_map = inputs.pop(\"overflow_to_sample_mapping\")\n",
    "    offset_mapping = inputs.pop(\"offset_mapping\")\n",
    "    \n",
    "    inputs[\"example_id\"] = []\n",
    "    # inputs[\"offset_mapping\"] = []\n",
    "\n",
    "    for i in range(len(inputs[\"input_ids\"])):\n",
    "        sample_idx = sample_map[i]\n",
    "        inputs[\"example_id\"].append(examples[\"id\"][sample_idx])\n",
    "        \n",
    "        # filter offset mapping\n",
    "        # sequence_ids = inputs.sequence_ids(i)\n",
    "        # inputs[\"offset_mapping\"].append([\n",
    "        #     o if sequence_ids[k] == 1 else None for k, o in enumerate(offset_mapping[i])\n",
    "        # ])\n",
    "\n",
    "    return inputs\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5da122d-8088-4ae4-9b70-a2e61cfccdd5",
   "metadata": {},
   "source": [
    "# Note\n",
    "Due to limited resource, I chose only 1000 of the original dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e0c369a7-3579-47d4-b8f0-12dd4e94784a",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset.set_format(\"torch\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ccb8c171-bcb0-4c8e-84eb-1f81abf88776",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a13d1d410ae94202a14c8e7c26367b35",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/1000 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "83241971ef524d2b89f381071df1c232",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/1000 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "from transformers import default_data_collator\n",
    "\n",
    "# preprocess datasets\n",
    "train_dataset = dataset[\"train\"].select(range(1000)).map(\n",
    "    preprocess_training_examples,\n",
    "    batched=True,\n",
    "    remove_columns=dataset[\"train\"].column_names,\n",
    ")\n",
    "\n",
    "validation_dataset = dataset[\"validation\"].select(range(1000)).map(\n",
    "    preprocess_validation_examples,\n",
    "    batched=True,\n",
    "    remove_columns=dataset[\"validation\"].column_names,\n",
    ")\n",
    "\n",
    "# Create dataloaders\n",
    "train_dataloader = DataLoader(\n",
    "    train_dataset,\n",
    "    shuffle=True,\n",
    "    # collate_fn=default_data_collator,\n",
    "    batch_size=8  # Adjust based on your GPU memory\n",
    ")\n",
    "\n",
    "eval_dataloader = DataLoader(\n",
    "    validation_dataset,\n",
    "    # collate_fn=default_data_collator,\n",
    "    batch_size=8  # Same as training batch size\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ec248812-25a5-4876-af48-10ca97855e28",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Tensor"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(train_dataset['input_ids'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "df6c3789-d22a-4b08-b075-308d6ec99e3c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>input_ids</th>\n",
       "      <th>token_type_ids</th>\n",
       "      <th>attention_mask</th>\n",
       "      <th>start_positions</th>\n",
       "      <th>end_positions</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[101, 2000, 3183, 2106, 1996, 6261, 2984, 9382...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...</td>\n",
       "      <td>130</td>\n",
       "      <td>137</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[101, 2054, 2003, 1999, 2392, 1997, 1996, 1028...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, ...</td>\n",
       "      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...</td>\n",
       "      <td>52</td>\n",
       "      <td>56</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[101, 1996, 13546, 1997, 1996, 6730, 2540, 201...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...</td>\n",
       "      <td>81</td>\n",
       "      <td>83</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[101, 2054, 2003, 1996, 24665, 23052, 2012, 10...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, ...</td>\n",
       "      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...</td>\n",
       "      <td>95</td>\n",
       "      <td>101</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[101, 2054, 7719, 2006, 2327, 1997, 1996, 2364...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, ...</td>\n",
       "      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...</td>\n",
       "      <td>33</td>\n",
       "      <td>39</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1027</th>\n",
       "      <td>[101, 2054, 2828, 1997, 5929, 2515, 1996, 2329...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, ...</td>\n",
       "      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...</td>\n",
       "      <td>25</td>\n",
       "      <td>26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1028</th>\n",
       "      <td>[101, 2054, 2120, 7071, 3303, 20773, 2000, 344...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, ...</td>\n",
       "      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...</td>\n",
       "      <td>14</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1029</th>\n",
       "      <td>[101, 2129, 2172, 5356, 2106, 20773, 2404, 204...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...</td>\n",
       "      <td>49</td>\n",
       "      <td>51</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1030</th>\n",
       "      <td>[101, 2054, 7064, 2086, 2101, 2044, 16864, 210...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...</td>\n",
       "      <td>70</td>\n",
       "      <td>70</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1031</th>\n",
       "      <td>[101, 2054, 2106, 20773, 1998, 20539, 2179, 19...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, ...</td>\n",
       "      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...</td>\n",
       "      <td>21</td>\n",
       "      <td>23</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1032 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              input_ids  \\\n",
       "0     [101, 2000, 3183, 2106, 1996, 6261, 2984, 9382...   \n",
       "1     [101, 2054, 2003, 1999, 2392, 1997, 1996, 1028...   \n",
       "2     [101, 1996, 13546, 1997, 1996, 6730, 2540, 201...   \n",
       "3     [101, 2054, 2003, 1996, 24665, 23052, 2012, 10...   \n",
       "4     [101, 2054, 7719, 2006, 2327, 1997, 1996, 2364...   \n",
       "...                                                 ...   \n",
       "1027  [101, 2054, 2828, 1997, 5929, 2515, 1996, 2329...   \n",
       "1028  [101, 2054, 2120, 7071, 3303, 20773, 2000, 344...   \n",
       "1029  [101, 2129, 2172, 5356, 2106, 20773, 2404, 204...   \n",
       "1030  [101, 2054, 7064, 2086, 2101, 2044, 16864, 210...   \n",
       "1031  [101, 2054, 2106, 20773, 1998, 20539, 2179, 19...   \n",
       "\n",
       "                                         token_type_ids  \\\n",
       "0     [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...   \n",
       "1     [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, ...   \n",
       "2     [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...   \n",
       "3     [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, ...   \n",
       "4     [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, ...   \n",
       "...                                                 ...   \n",
       "1027  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, ...   \n",
       "1028  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, ...   \n",
       "1029  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...   \n",
       "1030  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...   \n",
       "1031  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, ...   \n",
       "\n",
       "                                         attention_mask  start_positions  \\\n",
       "0     [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...              130   \n",
       "1     [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...               52   \n",
       "2     [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...               81   \n",
       "3     [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...               95   \n",
       "4     [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...               33   \n",
       "...                                                 ...              ...   \n",
       "1027  [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...               25   \n",
       "1028  [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...               14   \n",
       "1029  [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...               49   \n",
       "1030  [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...               70   \n",
       "1031  [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...               21   \n",
       "\n",
       "      end_positions  \n",
       "0               137  \n",
       "1                56  \n",
       "2                83  \n",
       "3               101  \n",
       "4                39  \n",
       "...             ...  \n",
       "1027             26  \n",
       "1028             15  \n",
       "1029             51  \n",
       "1030             70  \n",
       "1031             23  \n",
       "\n",
       "[1032 rows x 5 columns]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dataset.to_pandas()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7299c358-a173-4371-9098-dbd3e7009635",
   "metadata": {},
   "source": [
    "No longer using trainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "250dc4a2-be84-4bbb-a53f-b5d36ccef087",
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_dataset = dataset[\"train\"].map(\n",
    "#     preprocess_training_examples,\n",
    "#     batched=True,\n",
    "#     remove_columns=dataset[\"train\"].column_names,\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "87b6e894-75e2-4f13-9776-1934c5086ba8",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_save_path = \"model/baseline\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "24e720cb-7a1b-4cc4-97f7-29c5af3d49ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from transformers import TrainingArguments, Trainer\n",
    "\n",
    "# args = TrainingArguments(\n",
    "#     model_save_path,\n",
    "#     evaluation_strategy=\"no\",\n",
    "#     save_strategy=\"epoch\",\n",
    "#     learning_rate=2e-5,\n",
    "#     num_train_epochs=3,\n",
    "#     weight_decay=0.01,\n",
    "#     fp16=True,\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "1b2f64f6-2066-4d1b-bb54-73d97b7ef17a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# trainer = Trainer(\n",
    "#     model=model,\n",
    "#     args=args,\n",
    "#     train_dataset=subset_train_dataset,\n",
    "#     tokenizer=tokenizer,\n",
    "# )\n",
    "# trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "cb7fc6e5-628b-4513-88ad-8d97f5c69d69",
   "metadata": {},
   "outputs": [],
   "source": [
    "# validation_dataset.to_pandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "b4b90555-9a36-4691-ab32-40dfead8ba6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# validation_dataset = validation_dataset.remove_columns(['token_type_ids', 'offset_mapping'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "f8f0fc35-c59c-4d3b-a4ea-19cec95ba461",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>input_ids</th>\n",
       "      <th>token_type_ids</th>\n",
       "      <th>attention_mask</th>\n",
       "      <th>example_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[101, 2029, 5088, 2136, 3421, 1996, 10511, 201...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, ...</td>\n",
       "      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...</td>\n",
       "      <td>56be4db0acb8001400a502ec</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[101, 2029, 5088, 2136, 3421, 1996, 22309, 201...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, ...</td>\n",
       "      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...</td>\n",
       "      <td>56be4db0acb8001400a502ed</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[101, 2073, 2106, 3565, 4605, 2753, 2202, 2173...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, ...</td>\n",
       "      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...</td>\n",
       "      <td>56be4db0acb8001400a502ee</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[101, 2029, 5088, 2136, 2180, 3565, 4605, 2753...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, ...</td>\n",
       "      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...</td>\n",
       "      <td>56be4db0acb8001400a502ef</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[101, 2054, 3609, 2001, 2109, 2000, 17902, 199...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...</td>\n",
       "      <td>56be4db0acb8001400a502f0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1015</th>\n",
       "      <td>[101, 2054, 2001, 1996, 2171, 1997, 1996, 1442...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, ...</td>\n",
       "      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...</td>\n",
       "      <td>5733647e4776f419006609af</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1016</th>\n",
       "      <td>[101, 2054, 23050, 2001, 2328, 1999, 1996, 370...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...</td>\n",
       "      <td>5733647e4776f419006609b0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1017</th>\n",
       "      <td>[101, 2040, 2515, 1996, 6231, 1997, 2210, 1602...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, ...</td>\n",
       "      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...</td>\n",
       "      <td>5733647e4776f419006609b1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1018</th>\n",
       "      <td>[101, 2054, 6104, 2003, 1999, 3638, 1997, 1996...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, ...</td>\n",
       "      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...</td>\n",
       "      <td>5733647e4776f419006609b2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1019</th>\n",
       "      <td>[101, 2054, 2828, 1997, 2686, 1999, 8199, 2024...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...</td>\n",
       "      <td>573368044776f41900660a29</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1020 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              input_ids  \\\n",
       "0     [101, 2029, 5088, 2136, 3421, 1996, 10511, 201...   \n",
       "1     [101, 2029, 5088, 2136, 3421, 1996, 22309, 201...   \n",
       "2     [101, 2073, 2106, 3565, 4605, 2753, 2202, 2173...   \n",
       "3     [101, 2029, 5088, 2136, 2180, 3565, 4605, 2753...   \n",
       "4     [101, 2054, 3609, 2001, 2109, 2000, 17902, 199...   \n",
       "...                                                 ...   \n",
       "1015  [101, 2054, 2001, 1996, 2171, 1997, 1996, 1442...   \n",
       "1016  [101, 2054, 23050, 2001, 2328, 1999, 1996, 370...   \n",
       "1017  [101, 2040, 2515, 1996, 6231, 1997, 2210, 1602...   \n",
       "1018  [101, 2054, 6104, 2003, 1999, 3638, 1997, 1996...   \n",
       "1019  [101, 2054, 2828, 1997, 2686, 1999, 8199, 2024...   \n",
       "\n",
       "                                         token_type_ids  \\\n",
       "0     [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, ...   \n",
       "1     [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, ...   \n",
       "2     [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, ...   \n",
       "3     [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, ...   \n",
       "4     [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...   \n",
       "...                                                 ...   \n",
       "1015  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, ...   \n",
       "1016  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...   \n",
       "1017  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, ...   \n",
       "1018  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, ...   \n",
       "1019  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...   \n",
       "\n",
       "                                         attention_mask  \\\n",
       "0     [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...   \n",
       "1     [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...   \n",
       "2     [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...   \n",
       "3     [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...   \n",
       "4     [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...   \n",
       "...                                                 ...   \n",
       "1015  [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...   \n",
       "1016  [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...   \n",
       "1017  [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...   \n",
       "1018  [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...   \n",
       "1019  [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...   \n",
       "\n",
       "                    example_id  \n",
       "0     56be4db0acb8001400a502ec  \n",
       "1     56be4db0acb8001400a502ed  \n",
       "2     56be4db0acb8001400a502ee  \n",
       "3     56be4db0acb8001400a502ef  \n",
       "4     56be4db0acb8001400a502f0  \n",
       "...                        ...  \n",
       "1015  5733647e4776f419006609af  \n",
       "1016  5733647e4776f419006609b0  \n",
       "1017  5733647e4776f419006609b1  \n",
       "1018  5733647e4776f419006609b2  \n",
       "1019  573368044776f41900660a29  \n",
       "\n",
       "[1020 rows x 4 columns]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eval_dataloader.dataset.to_pandas()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a0d6a4c-7be9-4c6d-9b20-42854c874628",
   "metadata": {},
   "source": [
    "# Note\n",
    "Due to limited resource, I limited epochs to 3 for now."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "effe5c6f-7c64-4acc-94ce-59c218adaf2b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6f767e7520164e8787966332cf18d31e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/129 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Loss: 4.1854470940523365\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4d86846099034197906026afc9fd9786",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/129 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2, Loss: 2.5369425891905792\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "92918511fdaf4363a3bc77911acccbab",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/129 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3, Loss: 1.3582624113836954\n"
     ]
    }
   ],
   "source": [
    "epochs = 3\n",
    "lr = 2e-5\n",
    "\n",
    "for i in range(epochs):\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "    for batch in tqdm(train_dataloader):\n",
    "        # Move to device\n",
    "        batch['input_ids'] = batch['input_ids'].to(device)\n",
    "        batch['attention_mask'] = batch['attention_mask'].to(device)\n",
    "        \n",
    "        batch = {k: v.to(device) for k, v in batch.items() \n",
    "                 if k in ['input_ids', 'attention_mask', 'start_positions', 'end_positions']}\n",
    "        \n",
    "        outputs = model(**batch)\n",
    "\n",
    "        loss = outputs.loss\n",
    "        total_loss += loss.item()\n",
    "    \n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "    print(f\"Epoch {i + 1}, Loss: {total_loss / len(train_dataloader)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "d05fcae9-764f-48a6-a79d-0d64fae0dcf0",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e3022fa6b34a4f98ac50ec3dcda9afb0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/128 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from evaluate import load as load_metric\n",
    "metric = load_metric('squad')\n",
    "\n",
    "model.eval()\n",
    "all_predictions = []\n",
    "all_references = []\n",
    "\n",
    "for batch in tqdm(eval_dataloader):\n",
    "    with torch.no_grad():\n",
    "        batch['input_ids'] = batch['input_ids'].to(device)\n",
    "        batch['attention_mask'] = batch['attention_mask'].to(device)\n",
    "        \n",
    "        outputs = model(**{k: batch[k] for k in ['input_ids', 'attention_mask']})\n",
    "        \n",
    "        # process predictions\n",
    "        for i in range(batch['input_ids'].size(0)):\n",
    "            # Get token indices for prediction\n",
    "            start_pred = torch.argmax(outputs.start_logits[i]).item()\n",
    "            end_pred = torch.argmax(outputs.end_logits[i]).item()\n",
    "            \n",
    "            # decode prediction\n",
    "            input_ids = batch['input_ids'][i].tolist()\n",
    "            predicted_answer = tokenizer.decode(\n",
    "                input_ids[start_pred:end_pred+1], \n",
    "                skip_special_tokens=True\n",
    "            )\n",
    "            \n",
    "            # ground truth!!\n",
    "            example = dataset['validation'][i]\n",
    "            references = example['answers']['text']\n",
    "            \n",
    "            all_predictions.append(predicted_answer)\n",
    "            all_references.append(references)\n",
    "     \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "fd48699d-3d3c-40be-84f4-7de7585a61e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# would have to change to handle it somewhere else\n",
    "example_ids = dataset[\"validation\"].select(range(1000))[\"id\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70906f0a-2cad-4737-a5b8-882ba0945303",
   "metadata": {},
   "outputs": [],
   "source": [
    "# there was an issue with the predictions and references list, so I had to reformat it\n",
    "# not sure if this is doing it correctly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "1148496d-4651-4662-b1b1-29e98a8f4afe",
   "metadata": {},
   "outputs": [],
   "source": [
    "formatted_predictions = [\n",
    "    {\"id\": example_id, \"prediction_text\": pred_text}\n",
    "    for example_id, pred_text in zip(example_ids, all_predictions)\n",
    "]\n",
    "\n",
    "formatted_references = [\n",
    "    {\"id\": example_id, \"answers\": {\"text\": ref_texts, \"answer_start\": [0] * len(ref_texts)}}\n",
    "    for example_id, ref_texts in zip(example_ids, all_references)\n",
    "]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "d857b4d2-edcc-4dea-803a-dc3a15d53d0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "results = metric.compute(predictions=formatted_predictions, references=formatted_references)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "67331818-62ab-423d-b296-3e7315fdb942",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Exact Match (EM) Score: 0.40\n",
      "F1 Score: 0.65\n"
     ]
    }
   ],
   "source": [
    "print(f\"Exact Match (EM) Score: {results['exact_match']:.2f}\")\n",
    "print(f\"F1 Score: {results['f1']:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49cba767-e5e2-4f7a-8ca3-ef96cf0aa97d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01f4d023-db92-4578-a946-1c9facb4acf5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
